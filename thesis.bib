@article{CC90,
  author    = {E. J. Chikofsky and J. H. Cross},
  title     = {Reverse Engineering and Design Recovery: A Taxonomy},
  journal   = {IEEE Software},
  year      = 1990,
  volume    = 7,
  number    = 1,
  pages     = {13--17},
  publisher = {IEEE Computer Society Press}
}

@inproceedings{left-right,
  TITLE = {{Brief Announcement: Left-Right - A Concurrency Control Technique with Wait-Free Population Oblivious Reads}},
  AUTHOR = {Ramalhete, Pedro and Correia, Andreia},
  URL = {https://hal.science/hal-01207881},
  BOOKTITLE = {{DISC 2015}},
  ADDRESS = {Tokyo, Japan},
  ORGANIZATION = {{Toshimitsu Masuzawa and Koichi Wada}},
  EDITOR = {Yoram Moses and Matthieu Roy},
  PUBLISHER = {{Springer-Verlag Berlin Heidelberg}},
  SERIES = {29th International Symposium on Distributed Computing},
  VOLUME = {LNCS 9363},
  YEAR = {2015},
  MONTH = Oct,
  PDF = {https://hal.science/hal-01207881/file/39-BA.pdf},
  HAL_ID = {hal-01207881},
  HAL_VERSION = {v1},
}

@misc{lockfree-xenium,
  author = {Manuel Pöter},
  title  = {xenium},
  url    = {https://github.com/mpoeter/xenium}
}

@misc{lockfree-DNedic,
  author = {Djordje Nedic},
  title  = {lockfree},
  url    = {https://github.com/DNedic/lockfree}
}

@misc{dekker-fence-impl,
  author = {Anthony Williams},
  title  = {Implementing Dekker's algorithm with Fences},
  url    = {https://www.justsoftwaresolutions.co.uk/threading/implementing_dekkers_algorithm_with_fences.html}
}

@article{mcs-lock,
  author     = {Mellor-Crummey, John M. and Scott, Michael L.},
  title      = {Synchronization without contention},
  year       = {1991},
  issue_date = {Apr. 1991},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {19},
  number     = {2},
  issn       = {0163-5964},
  url        = {https://doi.org/10.1145/106975.106999},
  doi        = {10.1145/106975.106999},
  journal    = {SIGARCH Comput. Archit. News},
  month      = {apr},
  pages      = {269–278},
  numpages   = {10}
}
@misc{mcs-lock-impl,
  author = {cbloom},
  title  = {MCS list-based lock},
  url    = {https://cbloomrants.blogspot.com/2011/07/07-18-11-mcs-list-based-lock_18.html}
}

@misc{mpmc-queue-impl,
  author = {cbloom},
  title  = {A look at some bounded queues - part 2},
  url    = {https://cbloomrants.blogspot.com/2011/07/07-30-11-look-at-some-bounded-queues.html}
}

@article{chase-lev-deque-impl,
  author     = {L\^{e}, Nhat Minh and Pop, Antoniu and Cohen, Albert and Zappa Nardelli, Francesco},
  title      = {Correct and efficient work-stealing for weak memory models},
  year       = {2013},
  issue_date = {August 2013},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {48},
  number     = {8},
  issn       = {0362-1340},
  url        = {https://doi.org/10.1145/2517327.2442524},
  doi        = {10.1145/2517327.2442524},
  abstract   = {Chase and Lev's concurrent deque is a key data structure in shared-memory parallel programming and plays an essential role in work-stealing schedulers. We provide the first correctness proof of an optimized implementation of Chase and Lev's deque on top of the POWER and ARM architectures: these provide very relaxed memory models, which we exploit to improve performance but considerably complicate the reasoning. We also study an optimized x86 and a portable C11 implementation, conducting systematic experiments to evaluate the impact of memory barrier optimizations. Our results demonstrate the benefits of hand tuning the deque code when running on top of relaxed memory models.},
  journal    = {SIGPLAN Not.},
  month      = {feb},
  pages      = {69-80},
  numpages   = {12},
  keywords   = {work-stealing, relaxed memory model, proof, lock-free algorithm}
}



@book{Whe95,
  author    = {Colin Wheildon},
  title     = {Type \& Layout},
  publisher = {Strathmore Press},
  note      = {(ISBN 0 9624891 5 8)},
  year      = 1995
}

@inproceedings{c11tester,
  author    = {Luo, Weiyu and Demsky, Brian},
  title     = {C11Tester: a race detector for C/C++ atomics},
  year      = {2021},
  isbn      = {9781450383172},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3445814.3446711},
  doi       = {10.1145/3445814.3446711},
  abstract  = {Writing correct concurrent code that uses atomics under the C/C++ memory model is extremely difficult. We present C11Tester, a race detector for the C/C++ memory model that can explore executions in a larger fragment of the C/C++ memory model than previous race detector tools. Relative to previous work, C11Tester's larger fragment includes behaviors that are exhibited by ARM processors. C11Tester uses a new constraint-based algorithm to implement modification order that is optimized to allow C11Tester to make decisions in terms of application-visible behaviors. We evaluate C11Tester on several benchmark applications, and compare C11Tester's performance to both tsan11rec, the state of the art tool that controls scheduling for C/C++; and tsan11, the state of the art tool that does not control scheduling.},
  booktitle = {Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
  pages     = {630-646},
  numpages  = {17},
  keywords  = {memory models, data races, concurrency, C++11},
  location  = {Virtual, USA},
  series    = {ASPLOS '21}
}

@article{cdschecker,
  author     = {Norris, Brian and Demsky, Brian},
  title      = {CDSchecker: checking concurrent data structures written with C/C++ atomics},
  year       = {2013},
  issue_date = {October 2013},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {48},
  number     = {10},
  issn       = {0362-1340},
  url        = {https://doi.org/10.1145/2544173.2509514},
  doi        = {10.1145/2544173.2509514},
  abstract   = {Writing low-level concurrent software has traditionally required intimate knowledge of the entire toolchain and often has involved coding in assembly. New language standards have extended C and C++ with support for low-level atomic operations and a weak memory model, enabling developers to write portable and efficient multithreaded code.Developing correct low-level concurrent code is well-known to be especially difficult under a weak memory model, where code behavior can be surprising. Building reliable concurrent software using C/C++ low-level atomic operations will likely require tools that help developers discover unexpected program behaviors.In this paper we present CDSChecker, a tool for exhaustively exploring the behaviors of concurrent code under the C/C++ memory model. We develop several novel techniques for modeling the relaxed behaviors allowed by the memory model and for minimizing the number of execution behaviors that CDSChecker must explore. We have used CDSChecker to exhaustively unit test several concurrent data structure implementations on specific inputs and have discovered errors in both a recently published C11 implementation of a work-stealing queue and a single producer, single consumer queue implementation.},
  journal    = {SIGPLAN Not.},
  month      = {oct},
  pages      = {131-150},
  numpages   = {20},
  keywords   = {relaxed memory model, model checking}
}

@inproceedings{genmc,
  author    = {Kokologiannakis, Michalis
               and Vafeiadis, Viktor},
  editor    = {Silva, Alexandra
               and Leino, K. Rustan M.},
  title     = {GenMC: A Model Checker for Weak Memory Models},
  booktitle = {Computer Aided Verification},
  year      = {2021},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {427--440},
  abstract  = {GenMC is an LLVM-based state-of-the-art stateless model checker for concurrent C/C++ programs. Its modular infrastructure allows it to support complex memory models, such as RC11 and IMM, and makes it easy to extend to support further axiomatic memory models.},
  isbn      = {978-3-030-81685-8}
}

@misc{afl,
  author = {Michal Zalewski},
  title  = {American Fuzzy Lop},
  year   = {2014},
  url    = {https://lcamtuf.coredump.cx/afl/}
}

@inproceedings{muzz,
  author    = {Hongxu Chen and Shengjian Guo and Yinxing Xue and Yulei Sui and Cen Zhang and Yuekang Li and Haijun Wang and Yang Liu},
  title     = {{MUZZ}: Thread-aware Grey-box Fuzzing for Effective Bug Hunting in Multithreaded Programs},
  booktitle = {29th USENIX Security Symposium (USENIX Security 20)},
  year      = {2020},
  isbn      = {978-1-939133-17-5},
  pages     = {2325--2342},
  url       = {https://www.usenix.org/conference/usenixsecurity20/presentation/chen-hongxu},
  publisher = {USENIX Association},
  month     = aug
}

@inproceedings{conzzer,
  author = {Jiang, Zu-Ming and Bai, Jia-Ju and Lu, Kangjie and Hu, Shi-Min},
  year   = {2022},
  month  = {01},
  pages  = {},
  title  = {Context-Sensitive and Directional Concurrency Fuzzing for Data-Race Detection},
  doi    = {10.14722/ndss.2022.24296}
}

@inproceedings{10.1145/1736020.1736040,
  author    = {Burckhardt, Sebastian and Kothari, Pravesh and Musuvathi, Madanlal and Nagarakatte, Santosh},
  title     = {A randomized scheduler with probabilistic guarantees of finding bugs},
  year      = {2010},
  isbn      = {9781605588391},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/1736020.1736040},
  doi       = {10.1145/1736020.1736040},
  abstract  = {This paper presents a randomized scheduler for finding concurrency bugs. Like current stress-testing methods, it repeatedly runs a given test program with supplied inputs. However, it improves on stress-testing by finding buggy schedules more effectively and by quantifying the probability of missing concurrency bugs. Key to its design is the characterization of the depth of a concurrency bug as the minimum number of scheduling constraints required to find it. In a single run of a program with n threads and k steps, our scheduler detects a concurrency bug of depth d with probability at least 1/nkd-1. We hypothesize that in practice, many concurrency bugs (including well-known types such as ordering errors, atomicity violations, and deadlocks) have small bug-depths, and we confirm the efficiency of our schedule randomization by detecting previously unknown and known concurrency bugs in several production-scale concurrent programs.},
  booktitle = {Proceedings of the Fifteenth International Conference on Architectural Support for Programming Languages and Operating Systems},
  pages     = {167-178},
  numpages  = {12},
  keywords  = {concurrency, race conditions, randomized algorithms, testing},
  location  = {Pittsburgh, Pennsylvania, USA},
  series    = {ASPLOS XV}
}

@article{10.1145/1735970.1736040,
  author     = {Burckhardt, Sebastian and Kothari, Pravesh and Musuvathi, Madanlal and Nagarakatte, Santosh},
  title      = {A randomized scheduler with probabilistic guarantees of finding bugs},
  year       = {2010},
  issue_date = {March 2010},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {38},
  number     = {1},
  issn       = {0163-5964},
  url        = {https://doi.org/10.1145/1735970.1736040},
  doi        = {10.1145/1735970.1736040},
  abstract   = {This paper presents a randomized scheduler for finding concurrency bugs. Like current stress-testing methods, it repeatedly runs a given test program with supplied inputs. However, it improves on stress-testing by finding buggy schedules more effectively and by quantifying the probability of missing concurrency bugs. Key to its design is the characterization of the depth of a concurrency bug as the minimum number of scheduling constraints required to find it. In a single run of a program with n threads and k steps, our scheduler detects a concurrency bug of depth d with probability at least 1/nkd-1. We hypothesize that in practice, many concurrency bugs (including well-known types such as ordering errors, atomicity violations, and deadlocks) have small bug-depths, and we confirm the efficiency of our schedule randomization by detecting previously unknown and known concurrency bugs in several production-scale concurrent programs.},
  journal    = {SIGARCH Comput. Archit. News},
  month      = {mar},
  pages      = {167-178},
  numpages   = {12},
  keywords   = {concurrency, race conditions, randomized algorithms, testing}
}

@article{pct,
  author     = {Burckhardt, Sebastian and Kothari, Pravesh and Musuvathi, Madanlal and Nagarakatte, Santosh},
  title      = {A randomized scheduler with probabilistic guarantees of finding bugs},
  year       = {2010},
  issue_date = {March 2010},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {45},
  number     = {3},
  issn       = {0362-1340},
  url        = {https://doi.org/10.1145/1735971.1736040},
  doi        = {10.1145/1735971.1736040},
  abstract   = {This paper presents a randomized scheduler for finding concurrency bugs. Like current stress-testing methods, it repeatedly runs a given test program with supplied inputs. However, it improves on stress-testing by finding buggy schedules more effectively and by quantifying the probability of missing concurrency bugs. Key to its design is the characterization of the depth of a concurrency bug as the minimum number of scheduling constraints required to find it. In a single run of a program with n threads and k steps, our scheduler detects a concurrency bug of depth d with probability at least 1/nkd-1. We hypothesize that in practice, many concurrency bugs (including well-known types such as ordering errors, atomicity violations, and deadlocks) have small bug-depths, and we confirm the efficiency of our schedule randomization by detecting previously unknown and known concurrency bugs in several production-scale concurrent programs.},
  journal    = {SIGPLAN Not.},
  month      = {mar},
  pages      = {167-178},
  numpages   = {12},
  keywords   = {concurrency, race conditions, randomized algorithms, testing}
}

@inproceedings{pctwm,
  author    = {Gao, Mingyu and Chakraborty, Soham and Ozkan, Burcu Kulahcioglu},
  title     = {Probabilistic Concurrency Testing for Weak Memory Programs},
  year      = {2023},
  isbn      = {9781450399166},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3575693.3575729},
  doi       = {10.1145/3575693.3575729},
  abstract  = {The Probabilistic Concurrency Testing (PCT) algorithm that provides theoretical guarantees on the probability of detecting concurrency bugs does not apply to weak memory programs. The PCT algorithm builds on the interleaving semantics of sequential consistency, which does not hold for weak memory concurrency. It is because weak memory concurrency allows additional behaviors that cannot be produced by any interleaving execution.  
               
               In this paper, we generalize PCT to address weak memory concurrency and present Probabilistic Concurrency Testing for Weak Memory (PCTWM). We empirically evaluate PCTWM on a set of well-known weak memory program benchmarks in comparison to the state-of-the-art weak memory testing tool C11Tester. Our results show that PCTWM can detect concurrency bugs more frequently than C11Tester.},
  booktitle = {Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
  pages     = {603-616},
  numpages  = {14},
  keywords  = {Concurrency, Randomized algorithms, Testing, Weak memory},
  location  = {Vancouver, BC, Canada},
  series    = {ASPLOS 2023}
}

@inproceedings{rff,
  author    = {Meng, Ruijie and P\^{\i}rlea, George and Roychoudhury, Abhik and Sergey, Ilya},
  title     = {Greybox Fuzzing of Distributed Systems},
  year      = {2023},
  isbn      = {9798400700507},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3576915.3623097},
  doi       = {10.1145/3576915.3623097},
  abstract  = {Grey-box fuzzing is the lightweight approach of choice for finding bugs in sequential programs. It provides a balance between efficiency and effectiveness by conducting a biased random search over the domain of program inputs using a feedback function from observed test executions. For distributed system testing, however, the state-of-practice is represented today by only black-box tools that do not attempt to infer and exploit any knowledge of the system's past behaviours to guide the search for bugs.In this work, we present MALLORY: the first framework for grey-box fuzz-testing of distributed systems. Unlike popular black-box distributed system fuzzers, such as JEPSEN, that search for bugs by randomly injecting network partitions and node faults or by following human-defined schedules, MALLORY is adaptive. It exercises a novel metric to learn how to maximize the number of observed system behaviors by choosing different sequences of faults, thus increasing the likelihood of finding new bugs. Our approach relies on timeline-driven testing. MALLORY dynamically constructs Lamport timelines of the system behaviour and further abstracts these timelines into happens-before summaries, which serve as a feedback function guiding the fuzz campaign. Subsequently, MALLORY reactively learns a policy using Q-learning, enabling it to introduce faults guided by its real-time observation of the summaries.We have evaluated MALLORY on a diverse set of widely-used industrial distributed systems. Compared to the start-of-the-art black-box fuzzer JEPSEN, MALLORY explores 54.27\% more distinct states within 24 hours while achieving a speed-up of 2.24X. At the same time, MALLORY finds bugs 1.87X faster, thereby finding more bugs within the given time budget. MALLORY discovered 22 zero-day bugs (of which 18 were confirmed by developers), including 10 new vulnerabilities, in rigorously tested distributed systems such as Braft, Dqlite and Redis. 6 new CVEs have been assigned.},
  booktitle = {Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security},
  pages     = {1615-1629},
  numpages  = {15},
  keywords  = {distributed systems, greybox fuzzing, reactive system testing},
  location  = {<conf-loc>, <city>Copenhagen</city>, <country>Denmark</country>, </conf-loc>},
  series    = {CCS '23}
}

@inproceedings{schfuzz,
  title     = {Schfuzz: Detecting Concurrency Bugs with Feedback-Guided Fuzzing},
  author    = {Hiromasa Ito and Yutaka Matsubara and Hiroaki Takada},
  booktitle = {International Conference on Evaluation of Novel Approaches to Software Engineering},
  year      = {2023},
  url       = {https://api.semanticscholar.org/CorpusID:258362077}
}

@article{Weakestmo2,
  author     = {Moiseenko, Evgenii and Kokologiannakis, Michalis and Vafeiadis, Viktor},
  title      = {Model checking for a multi-execution memory model},
  year       = {2022},
  issue_date = {October 2022},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {6},
  number     = {OOPSLA2},
  url        = {https://doi.org/10.1145/3563315},
  doi        = {10.1145/3563315},
  abstract   = {Multi-execution memory models, such as Promising and Weakestmo, are an advanced class of weak memory  
                consistency models that justify certain outcomes of a concurrent program by considering multiple candidate executions collectively. While this key characteristic allows them to support effective compilation to hardware models and a wide range of compiler optimizations, it makes reasoning about them substantially more difficult. In particular, we observe that Promising and Weakestmo inhibit effective model checking because they allow some suprisingly weak behaviors that cannot be generated by examining one execution at a time.  
                
                We therefore introduce Weakestmo2, a strengthening of Weakestmo by constraining its multi-execution  
                nature, while preserving the important properties of Weakestmo: DRF theorems, compilation to hardware models, and correctness of local program transformations. Our strengthening rules out a class of surprisingly weak program behaviors, which we attempt to characterize with the help of two novel properties: load buffering race freedom and certification locality. In addition, we develop WMC, a model checker for Weakestmo2 with performance close to that of the best tools for per-execution models.},
  journal    = {Proc. ACM Program. Lang.},
  month      = {oct},
  articleno  = {152},
  numpages   = {28},
  keywords   = {Weak memory models, model checking}
}

@inproceedings{ConFuzz,
  author    = {Vinesh, Nischai
               and Sethumadhavan, M.},
  editor    = {Luhach, Ashish Kumar
               and Kosa, Janos Arpad
               and Poonia, Ramesh Chandra
               and Gao, Xiao-Zhi
               and Singh, Dharm},
  title     = {ConFuzz---A Concurrency Fuzzer},
  booktitle = {First International Conference on Sustainable Technologies for Computational Intelligence},
  year      = {2020},
  publisher = {Springer Singapore},
  address   = {Singapore},
  pages     = {667--691},
  abstract  = {Concurrency bugs are as equally vulnerable as the bugs found in the single-threaded programs and these bugs can be exploited using concurrency attacks. Unfortunately, there is not much literature available in detecting various kinds of concurrency issues in a multi-threaded program due to its complexity and uncertainty. In this paper, we aim at detecting concurrency bugs by using directed evolutionary fuzzing with the help of static analysis of the source code. Concurrency bug detection involves two main entities: an input and a particular thread execution order. The evolutionary part of fuzzing will prefer inputs that involve memory access patterns across threads (data flow interleaving) and thread ordering that disturb the data dependence more and direct them to trigger concurrency bugs. This paper suggests the idea of a concurrency fuzzer, which is first of its kind. We use a combination of LLVM, Thread Sanitizer and fuzzing techniques to detect various concurrency issues in an application. The source code of the application is statically analyzed for various paths, from the different thread related function calls to the main function. Every basic block in these paths are assigned a unique ID and a weight based on the distance of the basic block from the thread function calls. These basic blocks are instrumented to print their ID and weight upon execution. The knowledge about the basic blocks in the sliced paths are used to generate new sets of inputs from the old ones, thus covering even more basic blocks in the path and thereby increasing the chances of hitting a concurrency warning. We use Thread Sanitizer present in the LLVM compiler infrastructure to detect the concurrency bug warnings while executing each input. The inputs are directed to discover even new address locations with possible concurrency issues. The system was tested on three simple multi-threaded applications pigz, pbzip2, and pixz. The results show a quicker detection of unique addresses in the application with possible concurrency issues.},
  isbn      = {978-981-15-0029-9}
}

@article{AutoInter,
  author     = {Ko, Youngjoo and Zhu, Bin and Kim, Jong},
  title      = {Fuzzing with automatically controlled interleavings to detect concurrency bugs},
  year       = {2022},
  issue_date = {Sep 2022},
  publisher  = {Elsevier Science Inc.},
  address    = {USA},
  volume     = {191},
  number     = {C},
  issn       = {0164-1212},
  url        = {https://doi.org/10.1016/j.jss.2022.111379},
  doi        = {10.1016/j.jss.2022.111379},
  journal    = {J. Syst. Softw.},
  month      = {sep},
  numpages   = {15},
  keywords   = {Reliability, Multi-threading, Concurrency vulnerabilities, Bug detection, Fuzzing}
}

@inproceedings{heuristic,
  author    = {Liu, Changming and Zou, Deqing and Luo, Peng and Zhu, Bin B. and Jin, Hai},
  title     = {A Heuristic Framework to Detect Concurrency Vulnerabilities},
  year      = {2018},
  isbn      = {9781450365697},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3274694.3274718},
  doi       = {10.1145/3274694.3274718},
  abstract  = {With a growing demand of concurrent software to exploit multi-core hardware capability, concurrency vulnerabilities have become an inevitable threat to the security of today's IT industry. Existing concurrent program detection schemes focus mainly on detecting concurrency errors such as data races, atomicity violation, etc., with little attention paid to detect concurrency vulnerabilities that may be exploited to infringe security. In this paper, we propose a heuristic framework that combines both static analysis and fuzz testing to detect targeted concurrency vulnerabilities such as concurrency buffer overflow, double free, and use-after-free. The static analysis locates sensitive concurrent operations in a concurrent program, categorizes each finding into a potential type of concurrency vulnerability, and determines the execution order of the sensitive operations in each finding that would trigger the suspected concurrency vulnerability. The results are then plugged into the fuzzer with the execution order fixed by the static analysis in order to trigger the suspected concurrency vulnerabilities.In order to introduce more variance which increases possibility that the concurrency errors can be triggered, we also propose manipulation of thread scheduling priority to enable a fuzzer such as AFL to effectively explore thread interleavings in testing a concurrent program. To the best of our knowledge, this is the first fuzzer that is capable of effectively exploring concurrency errors.In evaluating the proposed heuristic framework with a benchmark suit of six real-world concurrent C programs, the framework detected two concurrency vulnerabilities for the proposed concurrency vulnerability detection, both being confirmed to be true positives, and produced three new crashes for the proposed interleaving exploring fuzzer that existing fuzzers could not produce. These results demonstrate the power and effectiveness of the proposed heuristic framework in detecting concurrency errors and vulnerabilities.},
  booktitle = {Proceedings of the 34th Annual Computer Security Applications Conference},
  pages     = {529-541},
  numpages  = {13},
  keywords  = {Concurrency Vulnerabilities, Fuzzing Test, Thread Schedule},
  location  = {San Juan, PR, USA},
  series    = {ACSAC '18}
}

@inproceedings{sel4,
  author    = {Klein, Gerwin and Elphinstone, Kevin and Heiser, Gernot and Andronick, June and Cock, David and Derrin, Philip and Elkaduwe, Dhammika and Engelhardt, Kai and Kolanski, Rafal and Norrish, Michael and Sewell, Thomas and Tuch, Harvey and Winwood, Simon},
  title     = {seL4: formal verification of an OS kernel},
  year      = {2009},
  isbn      = {9781605587523},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/1629575.1629596},
  doi       = {10.1145/1629575.1629596},
  abstract  = {Complete formal verification is the only known way to guarantee that a system is free of programming errors.We present our experience in performing the formal, machine-checked verification of the seL4 microkernel from an abstract specification down to its C implementation. We assume correctness of compiler, assembly code, and hardware, and we used a unique design approach that fuses formal and operating systems techniques. To our knowledge, this is the first formal proof of functional correctness of a complete, general-purpose operating-system kernel. Functional correctness means here that the implementation always strictly follows our high-level abstract specification of kernel behaviour. This encompasses traditional design and implementation safety properties such as the kernel will never crash, and it will never perform an unsafe operation. It also proves much more: we can predict precisely how the kernel will behave in every possible situation.seL4, a third-generation microkernel of L4 provenance, comprises 8,700 lines of C code and 600 lines of assembler. Its performance is comparable to other high-performance L4 kernels.},
  booktitle = {Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles},
  pages     = {207-220},
  numpages  = {14},
  keywords  = {isabelle/hol, l4, microkernel, sel4},
  location  = {Big Sky, Montana, USA},
  series    = {SOSP '09}
}

@inproceedings{infer,
  author    = {Calcagno, Cristiano
               and Distefano, Dino},
  editor    = {Bobaru, Mihaela
               and Havelund, Klaus
               and Holzmann, Gerard J.
               and Joshi, Rajeev},
  title     = {Infer: An Automatic Program Verifier for Memory Safety of C Programs},
  booktitle = {NASA Formal Methods},
  year      = {2011},
  publisher = {Springer Berlin Heidelberg},
  address   = {Berlin, Heidelberg},
  pages     = {459--465},
  abstract  = {Infer is a new automatic program verification tool aimed at proving memory safety of C programs. It attempts to build a compositional proof of the program at hand by composing proofs of its constituent modules (functions/procedures). Bugs are extracted from failures of proof attempts. We describe the main features of Infer and some of the main ideas behind it.},
  isbn      = {978-3-642-20398-5}
}

@article{RacerD,
  author     = {Blackshear, Sam and Gorogiannis, Nikos and O'Hearn, Peter W. and Sergey, Ilya},
  title      = {RacerD: compositional static race detection},
  year       = {2018},
  issue_date = {November 2018},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {2},
  number     = {OOPSLA},
  url        = {https://doi.org/10.1145/3276514},
  doi        = {10.1145/3276514},
  abstract   = {Automatic static detection of data races is one of the most basic problems in reasoning about concurrency. We present RacerD—a static program analysis for detecting data races in Java programs which is fast, can scale to large code, and has proven effective in an industrial software engineering scenario. To our knowledge, RacerD is the first inter-procedural, compositional data race detector which has been shown to have non-trivial precision and impact. Due to its compositionality, it can analyze code changes quickly, and this allows it to perform continuous reasoning about a large, rapidly changing codebase as part of deployment within a continuous integration ecosystem. In contrast to previous static race detectors, its design favors reporting high-confidence bugs over ensuring their absence. RacerD has been in deployment for over a year at Facebook, where it has flagged over 2500 issues that have been fixed by developers before reaching production. It has been important in enabling the development of new code as well as fixing old code: it helped support conversion of part of the main Facebook Android app from a single-threaded to a multi-threaded architecture. In this paper we describe RacerD’s design, implementation, deployment and impact.},
  journal    = {Proc. ACM Program. Lang.},
  month      = {oct},
  articleno  = {144},
  numpages   = {28},
  keywords   = {Concurrency, Concurrent Separation Logic, Race Freedom, Static Analysis}
}

@inproceedings{ASAN,
  author    = {Konstantin Serebryany and Derek Bruening and Alexander Potapenko and Dmitriy Vyukov},
  title     = {{AddressSanitizer}: A Fast Address Sanity Checker},
  booktitle = {2012 USENIX Annual Technical Conference (USENIX ATC 12)},
  year      = {2012},
  isbn      = {978-931971-93-5},
  address   = {Boston, MA},
  pages     = {309--318},
  url       = {https://www.usenix.org/conference/atc12/technical-sessions/presentation/serebryany},
  publisher = {USENIX Association},
  month     = jun
}

@inproceedings{TSAN,
  author    = {Serebryany, Konstantin and Iskhodzhanov, Timur},
  title     = {ThreadSanitizer: data race detection in practice},
  year      = {2009},
  isbn      = {9781605587936},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/1791194.1791203},
  doi       = {10.1145/1791194.1791203},
  abstract  = {Data races are a particularly unpleasant kind of threading bugs. They are hard to find and reproduce -- you may not observe a bug during the entire testing cycle and will only see it in production as rare unexplainable failures. This paper presents ThreadSanitizer -- a dynamic detector of data races. We describe the hybrid algorithm (based on happens-before and locksets) used in the detector. We introduce what we call dynamic annotations -- a sort of race detection API that allows a user to inform the detector about any tricky synchronization in the user program. Various practical aspects of using ThreadSanitizer for testing multithreaded C++ code at Google are also discussed.},
  booktitle = {Proceedings of the Workshop on Binary Instrumentation and Applications},
  pages     = {62-71},
  numpages  = {10},
  keywords  = {testing, dynamic data race detection, concurrency bugs, Valgrind},
  location  = {New York, New York, USA},
  series    = {WBIA '09}
}

@article{SC,
  author   = {Lamport},
  journal  = {IEEE Transactions on Computers},
  title    = {How to Make a Multiprocessor Computer That Correctly Executes Multiprocess Programs},
  year     = {1979},
  volume   = {C-28},
  number   = {9},
  pages    = {690-691},
  keywords = {Computer design;concurrent computing;hardware correctness;multiprocessing;parallel processing},
  doi      = {10.1109/TC.1979.1675439}
}

@article{TSO,
  author    = {Peter Sewell and
               Susmit Sarkar and
               Scott Owens and
               Francesco Zappa Nardelli and
               Magnus O. Myreen},
  title     = {x86-TSO: a rigorous and usable programmer's model for x86 multiprocessors},
  journal   = {Commun. {ACM}},
  volume    = {53},
  number    = {7},
  pages     = {89--97},
  year      = {2010},
  url       = {https://doi.org/10.1145/1785414.1785443},
  doi       = {10.1145/1785414.1785443},
  timestamp = {Tue, 06 Nov 2018 12:51:37 +0100},
  biburl    = {https://dblp.org/rec/journals/cacm/SewellSONM10.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@book{PSO,
  author    = {SPARC International, Inc., CORPORATE},
  title     = {The SPARC architecture manual: version 8},
  year      = {1992},
  isbn      = {0138250014},
  publisher = {Prentice-Hall, Inc.},
  address   = {USA}
}



@article{java,
  author     = {Manson, Jeremy and Pugh, William and Adve, Sarita V.},
  title      = {The Java memory model},
  year       = {2005},
  issue_date = {January 2005},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {40},
  number     = {1},
  issn       = {0362-1340},
  url        = {https://doi.org/10.1145/1047659.1040336},
  doi        = {10.1145/1047659.1040336},
  abstract   = {This paper describes the new Java memory model, which has been revised as part of Java 5.0. The model specifies the legal behaviors for a multithreaded program; it defines the semantics of multithreaded Java programs and partially determines legal implementations of Java virtual machines and compilers.The new Java model provides a simple interface for correctly synchronized programs -- it guarantees sequential consistency to data-race-free programs. Its novel contribution is requiring that the behavior of incorrectly synchronized programs be bounded by a well defined notion of causality. The causality requirement is strong enough to respect the safety and security properties of Java and weak enough to allow standard compiler and hardware optimizations. To our knowledge, other models are either too weak because they do not provide for sufficient safety/security, or are too strong because they rely on a strong notion of data and control dependences that precludes some standard compiler transformations.Although the majority of what is currently done in compilers is legal, the new model introduces significant differences, and clearly defines the boundaries of legal transformations. For example, the commonly accepted definition for control dependence is incorrect for Java, and transformations based on it may be invalid.In addition to providing the official memory model for Java, we believe the model described here could prove to be a useful basis for other programming languages that currently lack well-defined models, such as C++ and C#.},
  journal    = {SIGPLAN Not.},
  month      = {jan},
  pages      = {378-391},
  numpages   = {14},
  keywords   = {multithreading, memory model, concurrency, Java}
}

@article{c++model,
  author     = {Batty, Mark and Owens, Scott and Sarkar, Susmit and Sewell, Peter and Weber, Tjark},
  title      = {Mathematizing C++ concurrency},
  year       = {2011},
  issue_date = {January 2011},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {46},
  number     = {1},
  issn       = {0362-1340},
  url        = {https://doi.org/10.1145/1925844.1926394},
  doi        = {10.1145/1925844.1926394},
  abstract   = {Shared-memory concurrency in C and C++ is pervasive in systems programming, but has long been poorly defined. This motivated an ongoing shared effort by the standards committees to specify concurrent behaviour in the next versions of both languages. They aim to provide strong guarantees for race-free programs, together with new (but subtle) relaxed-memory atomic primitives for high-performance concurrent code. However, the current draft standards, while the result of careful deliberation, are not yet clear and rigorous definitions, and harbour substantial problems in their details.In this paper we establish a mathematical (yet readable) semantics for C++ concurrency. We aim to capture the intent of the current (`Final Committee') Draft as closely as possible, but discuss changes that fix many of its problems. We prove that a proposed x86 implementation of the concurrency primitives is correct with respect to the x86-TSO model, and describe our Cppmem tool for exploring the semantics of examples, using code generated from our Isabelle/HOL definitions.Having already motivated changes to the draft standard, this work will aid discussion of any further changes, provide a correctness condition for compilers, and give a much-needed basis for analysis and verification of concurrent C and C++ programs.},
  journal    = {SIGPLAN Not.},
  month      = {jan},
  pages      = {55-66},
  numpages   = {12},
  keywords   = {semantics, relaxed memory models}
}




@article{c++model-proposal,
  author     = {Boehm, Hans-J. and Adve, Sarita V.},
  title      = {Foundations of the C++ concurrency memory model},
  year       = {2008},
  issue_date = {June 2008},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {43},
  number     = {6},
  issn       = {0362-1340},
  url        = {https://doi.org/10.1145/1379022.1375591},
  doi        = {10.1145/1379022.1375591},
  abstract   = {Currently multi-threaded C or C++ programs combine a single-threaded programming language with a separate threads library. This is not entirely sound [7].We describe an effort, currently nearing completion, to address these issues by explicitly providing semantics for threads in the next revision of the C++ standard. Our approach is similar to that recently followed by Java [25], in that, at least for a well-defined and interesting subset of the language, we give sequentially consistent semantics to programs that do not contain data races. Nonetheless, a number of our decisions are often surprising even to those familiar with the Java effort:We (mostly) insist on sequential consistency for race-free programs, in spite of implementation issues that came to light after the Java work.We give no semantics to programs with data races. There are no benign C++ data races.We use weaker semantics for trylock than existing languages or libraries, allowing us to promise sequential consistency with an intuitive race definition, even for programs with trylock.This paper describes the simple model we would like to be able to provide for C++ threads programmers, and explain how this, together with some practical, but often under-appreciated implementation constraints, drives us towards the above decisions.},
  journal    = {SIGPLAN Not.},
  month      = {jun},
  pages      = {68-78},
  numpages   = {11},
  keywords   = {c++, data race, memory consistency, memory model, sequential consistency, trylock}
}

@article{promise-c++model,
  author     = {Kang, Jeehoon and Hur, Chung-Kil and Lahav, Ori and Vafeiadis, Viktor and Dreyer, Derek},
  title      = {A promising semantics for relaxed-memory concurrency},
  year       = {2017},
  issue_date = {January 2017},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {52},
  number     = {1},
  issn       = {0362-1340},
  url        = {https://doi.org/10.1145/3093333.3009850},
  doi        = {10.1145/3093333.3009850},
  abstract   = {Despite many years of research, it has proven very difficult to develop a memory model for concurrent programming languages that adequately balances the conflicting desiderata of programmers, compilers, and hardware. In this paper, we propose the first relaxed memory model that (1) accounts for a broad spectrum of features from the C++11 concurrency model, (2) is implementable, in the sense that it provably validates many standard compiler optimizations and reorderings, as well as standard compilation schemes to x86-TSO and Power, (3) justifies simple invariant-based reasoning, thus demonstrating the absence of bad "out-of-thin-air" behaviors, (4) supports "DRF" guarantees, ensuring that programmers who use sufficient synchronization need not understand the full complexities of relaxed-memory semantics, and (5) defines the semantics of racy programs without relying on undefined behaviors, which is a prerequisite for applicability to type-safe languages like Java.  The key novel idea behind our model is the notion of *promises*: a thread may promise to execute a write in the future, thus enabling other threads to read from that write out of order. Crucially, to prevent out-of-thin-air behaviors, a promise step requires a thread-local certification that it will be possible to execute the promised write even in the absence of the promise. To establish confidence in our model, we have formalized most of our key results in Coq.},
  journal    = {SIGPLAN Not.},
  month      = {jan},
  pages      = {175-189},
  numpages   = {15},
  keywords   = {operational semantics, Weak memory models, C++11}
}

@inproceedings{promise2.0-c++model,
  title     = {Promising 2.0: Global optimizations in relaxed memory concurrency},
  abstract  = {For more than fifteen years, researchers have tried to support global optimizations in a usable semantics for a concurrent programming language, yet this task has been proven to be very difficult because of (1) the infamous {"}out of thin air{"} problem, and (2) the subtle interaction between global and thread-local optimizations. In this paper, we present a solution to this problem by redesigning a key component of the promising semantics (PS) of Kang et al. Our updated PS 2.0 model supports all the results known about the original PS model (i.e., thread-local optimizations, hardware mappings, DRF theorems), but additionally enables transformations based on global value-range analysis as well as register promotion (i.e., making accesses to a shared location local if the location is accessed by only one thread). PS 2.0 also resolves a problem with the compilation of relaxed RMWs to ARMv8, which required an unintended extra fence.},
  keywords  = {Compiler Optimizations, Operational Semantics, Relaxed Memory Concurrency},
  author    = {Lee, {Sung Hwan} and Minki Cho and Anton Podkopaev and Soham Chakraborty and Hur, {Chung Kil} and Ori Lahav and Viktor Vafeiadis},
  note      = {Publisher Copyright: {\textcopyright} 2020 ACM.; 41st ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI 2020 ; Conference date: 15-06-2020 Through 20-06-2020},
  year      = {2020},
  month     = jun,
  day       = {11},
  doi       = {10.1145/3385412.3386010},
  language  = {אנגלית},
  series    = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
  publisher = {Association for Computing Machinery},
  pages     = {362--376},
  editor    = {Donaldson, {Alastair F.} and Emina Torlak},
  booktitle = {PLDI 2020 - Proceedings of the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation}
}

@inproceedings{Owicki-Gries-c11model,
  title     = {Owicki-Gries Reasoning for C11 Programs with Relaxed Dependencies},
  abstract  = {Deductive verification techniques for C11 programs have advanced significantly in recent years with the development of operational semantics and associated logics for increasingly large fragments of C11. However, these semantics and logics have been developed in a restricted setting to avoid the thin-air-read problem. In this paper, we propose an operational semantics that leverages an intra-thread partial order (called semantic dependencies) induced by a recently developed denotational event-structure-based semantics. We prove that our operational semantics is sound and complete with respect to the denotational semantics. We present an associated logic that generalises a recent Owicki-Gries framework for RC11 (repaired C11), and demonstrate the use of this logic over several example proofs.},
  address   = {},
  author    = {Wright, Daniel and Batty, Mark and Dongol, Brijesh},
  editor    = {Huisman, M and Pasareanu, C and Zhan, N},
  doi       = {10.1007/978-3-030-90870-6_13},
  isbn      = {3030908690},
  issn      = {0302-9743},
  journal   = {FORMAL METHODS, FM 2021},
  keywords  = {Computer Science, Interdisciplinary Applications;Computer Science, Theory & Methods;Science & Technology},
  language  = {eng},
  pages     = {18},
  publisher = {Springer Nature},
  series    = {Lecture Notes in Computer Science},
  subject   = {Computer Science;Technology},
  volume    = {13047},
  year      = {2021}
}


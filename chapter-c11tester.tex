\chapter{\label{cha:c11tester}Fuzzing with C11Tester}

C11Tester is a automatic testing tool that supports a large gragment of C/C++ weak memory model. This chapter presents an overview of C11Tester and customazation points of its plugable framework. Then the fuzzer's implementation is described. Finally we show the evaluation results on some of the benchmarks.

\section{Overview of C11Tester}

The C11Tester contains the following basic constructs: insstrumentation, scheduler, consistency checker and race detecter. 

C11Tester uses a LLVM pass compiler pass, CDSPass, to instrument all atomic operations, non-atomic accesses to shared memory locations, thread functions, mutex operations and fence operations by inserting a corresponding function call. The compiled program is linked with a dynamic library containing the function calls. 
C11Tester impelments a thread library that supports the same APIs of C++'s standard library and Posix thread library. The user's thread function calls will be mapped into user space fibers, instead of kernel space threads. Thus, all threads will be executed in a sequential manner with scheduling managed by a central scheduler, which is provided by the C11Tester. A context switching approach is applied to simulate the interleavings of threads to improve efficiency. 
Each atomic operation, thread creation and joining, mutex locks and unlocks, and memory fences will create a Action object, containing its type, value, memory order, thread id and other runtime information. Since all threads are sequenced during execution, each action will have a unique sequence number. The relations between actions, such as read from and synchronized with, are also maintained by the Action class. 

Although C/C++ programs under weak memory model do not use scheduling semantics, C11Tester does contain a central scheduler. It's worth noting that the scheduler do not simulate schedulings of threads, instead, it's designed to check actions of different threads in a total order. This is based on the implementation of mapping user's threads into fibers and checking them sequentially. All actions within the same thread will be checked following their sequence order, as a step, and the scheduler decides whether to check actions of other threads in the next step. Hence, two decisions will be made in each step, the behavior of the current action and the next thread to select. If the current action is a read, C11Tester will choose a write action to read from. Since the read-modify-write operations are instrumented with two functions, a read and a write, the scheduler ensures these two actions are atomic, i.e. to check them without switching to other threads in between. 

Memory locations are devided into two types: atomic locations and non-atomic locatios. Non-atomic access to shared memory locations is the source of introducing data races. C11Tester implements a race detecter to check data races. The race detecter will allocate a chunk of shadow memory for each of the non-atomic memory locations. Loading from or writing to non-atomic shared variables are instrumented with specific functions, which will register the current thread's state to the shadow memory. When multiple concurrent access to some shared non-atomic memory with at least one of them being a write is detected, a data race will be reported. 

Here we use an example to demonstrate the process of C11Tester's model checking procedure. 

\begin{lstlisting}[caption={P3}, label={P3}]
#include "librace.h"
#include <atomic>
#include <thread>
uint8_t data = {};
std::atomic<int> flag = { 1 };  

// thread 2
void t2() {
    store_8(&data, 0);          // cds_store8    
    flag.store(1, mo_release); 
}

// thread 3
void t3() {
    if (flag.load(mo_acquire))
        store_8(&data, 1);
}

// thread 1
int main() {
    std::thread thrd2(t2);
    std::thread thrd3(t3);
    thrd2.join();
    thrd3.join();
}
\end{lstlisting}

In this program, there are two shared variables: non-atomic variable data and atomic flag. The librace.h header is provided by C11Tester, containing the instrumented function store\_8 for non-atomic variables. The initialization of flag, which is non-atomic, deliberately uses 1 as the initial value. Since the c++ standard thread library internally calls POSIX APIs, the thread-related function calls will be hooked by C11Tester's dynamic library. 

After compilation, the model checker launches the program. After initializing the global variables, the model checker creates the first thread, which is the main thread and assign an tid, 1, to it. The first event is creating thrd2. After thrd2 is created and assigned an tid of 2, two threads, main and thrd2, are active. The model checker will randomly pick a thread to continue. Suppose the main thread is selected, the next event of it is creating thrd3. After creating thrd3, the next event of main is joining thrd2, so it becomes inactive. Now the current active threads are: thrd2 and thrd3. 

If the model checker selects thrd2, the two events in it, writing to data and flag, will be consumed, and the thrd2 is finished. Now thrd2 becomes joinable and the currently active threads are: main and thrd3. Suppose main is selected and after joining thrd2 it becomes inactive again. Then thrd3 becomes the only active thread so it will be executed without the need to make a choice. The first event in thrd3 is loading the value of flag. Since the store of flag in thrd2 has already been explored, the non-atomic initialization of flag is hidden in the modification order. Hence only the atomic store is visible to this load, and the rf relation also forms a synchronization-with relation between the two thread. When writing to the non-atomic data, the race detecter checks pervious access to that location. The store in thrd2 happens before the read in the current thread, which happens before the current store, so all events are totally ordered and no data race will be reported. 

Considering another case, suppose the model checker selects thrd3 after creating both threads. The load of flag will be executed and only the initialization of data is visible to it. After reading the initial value, the store of data is consumed. When thrd3 is finished, the stores in thrd2 will be executed. When writing to data, the race detecter checks previous actions relating to that memory location. The store in thrd3 is already explored and it has no happen before relations with the current store, so the two stores are concurrent and a data race is reported. 

One optimization that C11Tester implements is that it will consume writes with release and relaxed memory orders, only pausing on sc writes. This is because the sc order is part of the C/C++11 memory model so different sc order will result in different executions. Besides, consuming the weak writes will not lose the ability to cover possible executions. Consider the following example  \ref{P4}, 
\begin{lstlisting}[caption={P4}, label={P4}]
    std::atomic<int> var = {};      // (w0)
    void t2() {
        auto _ = var.load(acquire); // (r1)
    }
    void t3() {
        var.store(1, sc);           // (w1)
        var.store(2, release);      // (w2)
        var.store(3, release);      // (w3)
    }
\end{lstlisting}
after creating two threads, if t2 is selected first, r1 can only read from the initial value. If t3 is selected, the first event, w1, in this thread will be executed. The next two events are release writes, so the model checker will not re-select threads after w1. Instead, it will execute w2 and w3 until t3 is finished. Then it finds the only active thread is t2, so it selects t2. Now the set of available writes for r1 to read from becomes: w1, w2 and w3, and r1 is free to randomly select one of them. Although making thread decisions after each event is also feasible, the optimized version is more efficient and still able to cover all 4 possible executions.

Another optimization performed by C11Tester is that it avoids backtracking during exploration. To achieve this, it performs consistency checking at each step to ensure it's valid. It make decisions based on the implications of the memory model and already explored events. In \ref{P4} for example, if t3 has been explored, when choosing the rf relation for r1 in t2, the rf-set only contains w1, w2 and w3, where w0 is excluded. If r1 had selected w0 and the model checker continues until some point where the execution graph is found to be infeasible under the memory model, it would have to perform backtracking to make a different choise for r1. Consider another example \ref{P5}, 
\begin{lstlisting}[caption={P5}, label={P5}]
    std::atomic<int> var = {};      // (w0)
    void t2() {
        auto _1 = var.load(acquire); // (r1)
        auto _2 = var.load(acquire); // (r2)
    }
    void t3() {
        var.store(1, sc);           // (w1)
        var.store(2, release);      // (w2)
        var.store(3, release);      // (w3)
    }
\end{lstlisting}
if r1 has already seelcted w3 to read from, only w3 will be included in the rf-set for r2, becuase w3 $\xrightarrow{\text{rf}}$ r2 implies that w0-2 are modification-ordered before w3 and thus should not be visible to r2, which is sequence ordered after r1. Otherwise the RR coherence will be violated. Excluding infeasible writes from the rf-set ensures the rf's to be valid, which in turn avoids the backtracking efforts. 





\chapter{\label{cha:conclusion}Conclusions and Future
  Work}

This chapter gives an overview of the project's contributions. After
this overview, we will reflect on the results and draw some
conclusions. Finally, some ideas for future work will be discussed.

\section{Summary}

This project contributes a novel method of fuzzing C/C++ concurrent programs under weak memory models. We first reviewed the existing fuzzing techniques and categorized them according to their usage scenarios. As summarized before, fuzzing has been widely applied in sequential programs and sequentially consistent multi-threaded programs. Then we pointed out the lack of research in fuzzing for weak memory concurrency. We porposed a new fuzzing framework that utilizes execution graph semantics, as opposed to those using thread interleaving semantics. We set the metric to be the number of distinct execution graphs explored in a fixed number of iterations when comparing our fuzzer with naive random testers. We also proposed several different mutation strategies on a given execution graph. we implemented our new fuzzer on two state-of-the-art software testing platforms: C11Tester and GenMC. In both impelementations the fuzzing approach can explore a wider range of execution graphs compared to randomized testing. It is also shown that fuzzing is better at detecting rare executions while random testing tends to fall into ferquent executions more biasedly. In the implementation on GenMC, we compared the three mutation strategies according to their performance and efficiency. Our work has demonstrated that the feasibility of fuzzing for weak concurrency and proved its superiority over randomized testing.



\section{Discussion/Reflection}

The structure of our fuzzing framework differs slightly from some existing fuzzers, in the mutation function. For example, AFL uses program inputs as seeds and mutates existing interesting seeds to generate new ones. Similarly, RFF uses abstract schedules as seeds, mutating old schedules to create new ones. The mutation functions in such fuzzers can be expressed as $f_{mutate}: S \to S$, where $S$ represents the set of seeds.  In our framework, however, since seeds are defined as execution graph prefixes, they are mutated directly from execution graphs, which are also treated as the programs' outputs. Hence the mutation function is of the form: $f_{mutate}: G \to S$, where $G$ denotes the set of execution graphs. In some sense, our fuzzer "mutates the program outputs to generate inputs", much resembling a snake biting its own tail. This does not violate the principle of using fuzzing to guide new testing procedures with historical information, which is expected to outperform naive random testing that lacks any feedback and black-box fuzzing, as \cite{sage} suggests. Therefore, one corresponding question to ask is: should we keep track of graphs or prefixes, when they are connected in some way? Our design choice is to keep a list of prefixes, and evaluate their scores according to some metric, just like the way AFL maintains its seeds and performs power scheduling. However, it could be an alternative way to keep track of the execution graphs.

Besides, another design choice we made was about the interesting metic. In our fuzzing algorithm, we consider an execution to be interesting if its graph is new or rare. As a result, the fuzzer will explore as many distinct execution graphs as it can. A question can be asked: why not define interesting graphs as buggy execution graphs (or more interesting, at least), i.e. being biased towards those executions with bugs? Since in software testing we often care more about the bugs. One could argue that: 1, if no bugs have been found, the fuzzer still wants to mutate from previous executions; 2, if the tester finds a bug, the user can fix the bug and test it again, without the need of knowing more bugs. On the other hand, one could also suggest: 1, the more, the better; 2, a software testing tool should try harder to detect bugs in principle. In our fuzzer, we took the unbiased approach. Even it does not detect any bug in the end, it can still provide more confidence on the correctness of the user program due to its higher coverage of possible executions.

Thirdly, it is worth discussing whether to use model checking or fuzzing when testing programs. Model checkers tend to utilize systematic algorithms to explore the state space. GenMC, for example, implements an optimal algorithm that ensures each execution it explores is unique. However, model checkers often face the challenge of state space explosion, which can cause the search process to take a long time to complete. One might ask: why not run the model checker and stop it after a fixed amount of time or iterations? This approach would prevent infinite waiting times while still ensuring that each execution obtained is unique.
Naively, suppose the checker uses a depth first search strategy. If the first step yields two choices and the checker selects the left branch, the right branch will only be explored after all subtrees of the left branch have been fully explored. If we stop the search midway, we would only obtain results from the left branch. On the other hand, random testing can be thought of as both unbiased and biased. It is unbiased in that it does not have a predetermined preference for each exploration, but it is biased because some executions may have a lower probability of being explored than others. Our fuzzing approach, compared to random testing, aims to be more biased in the sense that it prioritizes those infrequent executions, and more unbiased in the sense of obtaining a more evenly distributed collection of results.



Lastly, a few comments about the thread interleavings. It is known that in weak memory concurrency we use execution graphs, instead of thread interleavings used in SC concurrency, to model executions. Since the SC memory model is a stronger model than weak memory models, the executions allowed under SC should be also allowed by weak memory models, therefore should be captured by execution graph semantics. In other words, using only execution graphs is sufficient in a more general sense. However, many model checkers also have a scheduler in their implementations. This scheduler is not the scheduler used for determining thread interleavings under SC, but is used for scheduling the order of adding events to execution graphs. Note that given a prefix $P$ and the next event $e$ in thread $t$, the following two scenarios are equivalent: 1, set $P$ as the prefix of next execution and force the scheduler to pick thread $t$ first, $e$ being the next event to be added; 2, add $e$ to prefix $P$ to compose a new prefix $P' = P \cup \{e\}$ and let the scheduler to add other events randomly. Hence, choosing which one of the two approaches is only an impelmentation issue, not an algorithmic difference. In our implementation on C11Tester, we chose the first approach, but that does not mean the fuzzer is still under the SC semantics.


\section{Future work}

In our current implementation, although the maximal cut performs best in a majority of benchmarks, still other mutations can outperform maximal cut in other cases. One continuation of this work could be develop a compound strategy that dynamically adjusts its preference on mutation methods. Besides the proposed mutation strategies, one could also develop other language or model specific mutations. The current implementation mutates the reads-from relation, including read-modify-writes. There could be other mutations targeting on relations such as modification-orders or primitives such as atomic fences, cas loops and atomic pointers. Besides, the fuzzing procedure relies on positive feedback. As discussed before, the fuzzing approach can improve the random testing, but it would be also possibel to derive some theoritical analysis on estimating how far it improves from the baseline on a given benchmark. The current fuzzer considers execution graphs to be interesting when they are unseen or rare. An alternative approach could be to record certain relations, such as the reads-from relation, and consider a graph interesting when it contains certain interesting relations.
